{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2_lowlvlapi",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvDpeYGnYyDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhVWfm72PfdX",
        "colab_type": "text"
      },
      "source": [
        "### 0.0 Installing Tensorflow 2.0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPNK7JUt7SoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojr_Cuf1MMOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxX_2fCoMPQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKukrAwJPnSU",
        "colab_type": "text"
      },
      "source": [
        "### 1.0 Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1m8omxBWhCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "from model import MyModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73bYntTtXolf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "39e9ae62-c795-4901-e350-b033ccc6c56b"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-dev20190608'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1jYCmD_NaMj",
        "colab_type": "text"
      },
      "source": [
        "###  2.0 Importing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLQKmWVDZCQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBWt6ToPZDna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Data\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "# Testing Data\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UBv3mPJZHnJ",
        "colab_type": "text"
      },
      "source": [
        "### 3.0 Importing the Model, Model Parameters & Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfKS_a4VNd9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Model Params\n",
        "num_inputs\n",
        "num_outputs\n",
        "'''\n",
        "\n",
        "model = MyModel(n_inputs, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxwxATS_O1xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "learning_rate = 0.001\n",
        "beta_1 = None\n",
        "beta_2 = None\n",
        "'''\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6dN1sq1ZPHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss', dtype=tf.float32)\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss', dtype=tf.float32)\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzBIkK9PZRwq",
        "colab_type": "text"
      },
      "source": [
        "### 4.0 Training Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6gIcceZZQYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(model, images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSmuauJMZYqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(model, images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4328dLlQd78",
        "colab_type": "text"
      },
      "source": [
        "### 5.0 Training Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB0gPekv45Nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Function\n",
        "def print_process(epoch, train_loss, train_accuracy, test_loss=None, test_accuracy=None):\n",
        "    if test_loss!=None and test_accuracy!=None:\n",
        "      template = 'Epoch {0:.0f} \\tLoss: {1:.4f} \\tAcc: {2:.f}% \\t\\tTest Loss: {3:.4f} \\tTest Acc: {4:.2f}%'\n",
        "      print(template.format(epoch+1,\n",
        "                            train_loss.result(),\n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(),\n",
        "                            test_accuracy.result()*100))\n",
        "    else:\n",
        "      template = 'Epoch {0:.0f} \\tLoss: {1:.4f} \\tAcc: {2:.2f}%'\n",
        "      print(template.format(epoch+1,\n",
        "                            train_loss.result(),\n",
        "                            train_accuracy.result()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucmUaX17Frfh",
        "colab_type": "text"
      },
      "source": [
        "### 6.0 Log Directory \n",
        "\n",
        "Set up summary writers to write the summaries to disk in a different logs directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLSOR-V-FW9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating File Directory\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "\n",
        "# Summary Writer\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qiT7QkrQoYC",
        "colab_type": "text"
      },
      "source": [
        "### 7.0 Training Cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sNNPGqrTISK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Use `tf.summary.scalar()` to log metrics (loss and accuracy) during training/testing \n",
        "within the scope of the summary writers to write the summaries to disk. You have control\n",
        "over which metrics to log and how often to do it\n",
        "'''\n",
        "\n",
        "\n",
        "def train(model, train_data, test_data=None, num_epochs=5):\n",
        "  \n",
        "  print('Training Commenced: ')\n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    for images, labels in train_data:               # Training Data\n",
        "      train_step(model, images, labels)\n",
        "    with train_summary_writer.as_default():\n",
        "      tf.summary.scalar(name='train_loss', train_loss.result(), step=epoch)\n",
        "      tf.summary.scalar(name='train_accuracy', train_accuracy.result(), step=epoch)\n",
        "\n",
        "    if test_data!=None:\n",
        "      for test_images, test_labels in test_data:    # Testing Data\n",
        "        test_step(model, test_images, test_labels)\n",
        "      with test_summary_writer.as_default():\n",
        "        tf.summary.scalar(name='test_loss', test_loss.result(), step=epoch)\n",
        "        tf.summary.scalar(name='test_accuracy', test_accuracy.result(), step=epoch)\n",
        "      \n",
        "    print_process(epoch, train_loss, train_accuracy, test_loss, test_accuracy)\n",
        "  \n",
        "  # Reset metrics every epoch\n",
        "  train_loss.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VXgzSoOWNLd",
        "colab_type": "text"
      },
      "source": [
        "### 8.0 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlV-oALoB8RH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "868c5bf3-9ccf-4f93-c4d1-5ab10f118159"
      },
      "source": [
        "train()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Commenced\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0609 16:18:31.807413 140279277197184 ag_logging.py:145] Entity <function train_step at 0x7f95177db840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "W0609 16:18:31.811664 140279277197184 ag_logging.py:145] Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function train_step at 0x7f95177db840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "WARNING: Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0609 16:18:32.032044 140279277197184 ag_logging.py:145] Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f95177cff28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "W0609 16:18:32.040365 140279277197184 ag_logging.py:145] Entity <function train_step at 0x7f95177db840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "W0609 16:18:32.043756 140279277197184 ag_logging.py:145] Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f95177cff28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "WARNING: Entity <function train_step at 0x7f95177db840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "WARNING: Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0609 16:20:53.660938 140279277197184 ag_logging.py:145] Entity <function test_step at 0x7f95177dbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "W0609 16:20:53.664834 140279277197184 ag_logging.py:145] Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function test_step at 0x7f95177dbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "WARNING: Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0609 16:20:58.451900 140279277197184 ag_logging.py:145] Entity <function test_step at 0x7f95177dbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "W0609 16:20:58.455674 140279277197184 ag_logging.py:145] Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function test_step at 0x7f95177dbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "WARNING: Entity <bound method MyModel.call of <__main__.MyModel object at 0x7f951957c668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.contrib'\n",
            "Epoch 1 \tLoss: 0.07 \tAcc: 97.76% \t\tTest Loss: 0.06 \tTest Acc: 98.13%\n",
            "Epoch 2 \tLoss: 0.05 \tAcc: 98.43% \t\tTest Loss: 0.06 \tTest Acc: 98.20%\n",
            "Epoch 3 \tLoss: 0.04 \tAcc: 98.80% \t\tTest Loss: 0.06 \tTest Acc: 98.26%\n",
            "Epoch 4 \tLoss: 0.03 \tAcc: 99.01% \t\tTest Loss: 0.06 \tTest Acc: 98.26%\n",
            "Epoch 5 \tLoss: 0.03 \tAcc: 99.15% \t\tTest Loss: 0.07 \tTest Acc: 98.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH0KOv6EQwp-",
        "colab_type": "text"
      },
      "source": [
        "### 9.0 Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye7GZQ-rCLoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/gradient_tape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGayPg7vTDEc",
        "colab_type": "text"
      },
      "source": [
        "### Code Reference\n",
        "\n",
        "- https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/r2/get_started.ipynb#scrollTo=-Iue509kgOyE\n",
        "- https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/advanced.ipynb"
      ]
    }
  ]
}